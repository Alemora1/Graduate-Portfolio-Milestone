{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libary Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the dare\n",
    "accidents = pd.read_csv('/Users/pedropereira/Downloads/US_Accidents_June20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the in a different variable. This is to save time if a new copy of the original data is needed\n",
    "df = accidents.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying sample fo the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View columns and data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting columns to drop\n",
    "delcols = ['ID','TMC','Source', 'End_Lat', 'End_Lng', 'Number', 'Street', 'Airport_Code', 'Weather_Timestamp', 'Civil_Twilight', \n",
    "           'Nautical_Twilight', 'Astronomical_Twilight']\n",
    "#Dropping columns\n",
    "df.drop(delcols, axis=1, inplace=True)\n",
    "#Replacing null values\n",
    "df.fillna(df.median(), inplace=True)\n",
    "#Replacing boolean values\n",
    "df.replace({True:1,False:0}, inplace=True)\n",
    "#Converting start and end time to datetime data type\n",
    "df.Start_Time =  pd.to_datetime(df.Start_Time)\n",
    "df.End_Time =  pd.to_datetime(df.End_Time)\n",
    "#Converting severity to factor\n",
    "df.Severity = df.Severity.astype(object)\n",
    "#Calculating duration in hours\n",
    "df['Duration'] = df.End_Time - df.Start_Time\n",
    "df['Duration'] = df['Duration'] / np.timedelta64(1, 'h')\n",
    "#Replacing outliers\n",
    "df.loc[df['Duration'] > 5, 'Duration'] = 0.74 \n",
    "df.loc[df['Duration'] < 0, 'Duration'] = 0.74 \n",
    "df.drop(columns=['Start_Time', 'End_Time', 'Description'], inplace = True)\n",
    "df.fillna(df.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploring the accident severity\n",
    "df.Severity.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the frequency of the structures\n",
    "plt.figure(figsize=(10,10))\n",
    "structural_conditions = df[['Turning_Loop', 'Traffic_Signal', 'Traffic_Calming', 'Stop', 'Station', 'Roundabout', 'Railway', 'No_Exit', 'Junction', 'Give_Way', 'Crossing', 'Bump', 'Amenity']]\n",
    "total = len(structural_conditions)\n",
    "z = structural_conditions.sum(axis=0)\n",
    "x = pd.DataFrame(z, columns=['Structure'])\n",
    "x.reset_index(inplace=True)\n",
    "x.rename(columns={'index':'Structure', 'Structure':'Frequency'}, inplace=True)\n",
    "x['Proportion'] = x['Frequency'] / total * 100\n",
    "x.sort_values(by=['Proportion'], ascending=False, inplace=True)\n",
    "sns.barplot(data= x, x =  x['Structure'], y= x['Proportion'])\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the frequency of other columns\n",
    "plt.figure(figsize=(40,40))\n",
    "un = df[[\"Side\", \"City\", \"County\", \"State\", \"Country\", \"Timezone\", \"Weather_Condition\", \"Zipcode\"]]\n",
    "un = un.nunique().reset_index()\n",
    "un.columns = ['feature','nunique']\n",
    "un.sort_values(by=[\"nunique\"], inplace = True)\n",
    "un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Independent columns\n",
    "X = df.drop(columns=['Severity', 'City', 'County', 'Zipcode', 'Country', 'Weather_Condition', 'Wind_Direction', \n",
    "                     'Roundabout', 'Bump', 'Turning_Loop', 'Traffic_Calming', 'State', 'Sunrise_Sunset', 'Timezone', \n",
    "                     'Stop', 'Amenity', 'Give_Way', 'No_Exit', 'Station', 'Railway' ], axis = 1)  \n",
    "#Dependent column\n",
    "y = df.Severity   \n",
    "#One hot encoding variables\n",
    "X = pd.get_dummies(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "#Creating hour column\n",
    "new_col = []\n",
    "for i in df['Start_Time']:\n",
    "    new_col.append(i.hour) \n",
    "df['hour'] = new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the day column\n",
    "new_col = []\n",
    "for i in df['Start_Time']:\n",
    "    new_col.append(i.day) \n",
    "df['day'] = new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the month column\n",
    "new_col = []\n",
    "for i in df['Start_Time']:\n",
    "    new_col.append(i.month) \n",
    "df['month'] = new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot by hour\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.title('Accident Frequency by Hour')\n",
    "sns.countplot(df['hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot by month\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.title('Accidents by Month')\n",
    "df.month.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot by day\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.title('Accident Frequency by Day')\n",
    "sns.countplot(df['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot severity by hour\n",
    "plt.figure(figsize=(7,7))\n",
    "x = df.groupby('hour')['Severity'].mean()\n",
    "x = pd.DataFrame(x)\n",
    "x.reset_index(inplace = True)\n",
    "x = x.sort_values(by = 'Severity', ascending = False)\n",
    "plt.title('Accident Severity by Hour')\n",
    "sns.barplot(data = x, x = 'hour', y = 'Severity', order = x.sort_values('Severity', ascending = False)['hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary containing US States and abbreviations\n",
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'American Samoa': 'AS',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Guam': 'GU',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Northern Mariana Islands':'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virgin Islands': 'VI',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading population file\n",
    "pop = pd.read_csv('Desktop/Population.csv')\n",
    "#Replacing pop file with abbreviation\n",
    "pop['State'].replace(us_state_abbrev, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining data by the abbreviations and aggregating count by population proportion\n",
    "x = pd.DataFrame(x)\n",
    "x.reset_index(inplace = True)\n",
    "x.prop = round(x.prop / 10)\n",
    "x.sort_values(by='prop', ascending = False)\n",
    "x.rename(columns={'Start_Lat':'Count'}, inplace = True)\n",
    "x.sort_values(by='prop', ascending = False)\n",
    "x = x.merge(pop, left_on = 'State', right_on = 'State')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating sample of the data\n",
    "df = accidents.sample(frac= 0.70, replace=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training and testing sets with 20% reserved for test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=20, max_depth = 20, random_state=0).fit(X_train, y_train)\n",
    "#Making predictions\n",
    "y_pred_test = rf.predict(X_test)\n",
    "#Displaying model accuracy\n",
    "round(rf.score(X_test, y_test), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying more detailed metrics and visual confusion matrix\n",
    "from sklearn import metrics\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (rf, metrics.classification_report(y_test, y_pred_test)))\n",
    "disp = metrics.plot_confusion_matrix(rf, X_test, y_test)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "print(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the most significant variables from the model\n",
    "plt.figure(figsize=(10,10))\n",
    "sorted_idx = rf.feature_importances_.argsort()\n",
    "plt.barh(X.columns[sorted_idx], rf.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Random Forest Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependent variable\n",
    "X = df.drop(columns=['Severity', 'City', 'County', 'Zipcode', 'Country', 'Weather_Condition', 'Wind_Direction', \n",
    "                     'Roundabout', 'Bump', 'Turning_Loop', 'Traffic_Calming', 'State', 'Sunrise_Sunset', 'Timezone', \n",
    "                     'Stop', 'Amenity', 'Give_Way', 'No_Exit', 'Station', 'Railway', 'Duration', 'Severe_Delay' ], axis = 1)  \n",
    "#Independent columns\n",
    "y = df.Severe_Delay  \n",
    "#One hot encoding variables\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training model and making predictions\n",
    "tree = tree.DecisionTreeClassifier(max_depth = 3)\n",
    "y_pred = tree.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "#Displaying algorithm metrics and confusion matrix plot\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (tree, metrics.classification_report(y_test, y_pred)))\n",
    "disp = metrics.plot_confusion_matrix(tree, X_test, y_test)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "print(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying decision tree\n",
    "plt.figure(figsize=(15,15))\n",
    "from sklearn.tree import plot_tree\n",
    "a = plot_tree(tree, \n",
    "              feature_names=X.columns, \n",
    "              class_names=str(np.unique(y.values)), \n",
    "              filled=True)\n",
    "              "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
